{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d201153c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FAST + CLEAN VERSION (Use in Jupyter Notebook)\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Load Dataset\n",
    "# ------------------------------\n",
    "df = pd.read_csv(\"/content/covtype.csv\")\n",
    "print(\"Initial Shape:\", df.shape)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. OUTLIER REMOVAL (IQR method for continuous cols)\n",
    "# ----------------------------------------------------\n",
    "def remove_outliers_iqr(data, cols):\n",
    "    clean_data = data.copy()\n",
    "    for col in cols:\n",
    "        Q1 = clean_data[col].quantile(0.25)\n",
    "        Q3 = clean_data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        clean_data = clean_data[(clean_data[col] >= lower) & (clean_data[col] <= upper)]\n",
    "    return clean_data\n",
    "\n",
    "continuous_cols = [\"Elevation\", \"Aspect\", \"Slope\"]\n",
    "df = remove_outliers_iqr(df, continuous_cols)\n",
    "print(\"After Outlier Removal:\", df.shape)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. DATASET STATISTICS\n",
    "# ------------------------------\n",
    "print(\"\\n==== BASIC STATISTICS ====\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n==== SKEWNESS BEFORE ====\")\n",
    "print(df[continuous_cols].skew())\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. SKEWNESS REDUCTION (Log1p transform)\n",
    "# ----------------------------------------------------\n",
    "for col in continuous_cols:\n",
    "    df[col] = np.log1p(df[col])    # apply and save\n",
    "\n",
    "print(\"\\n==== SKEWNESS AFTER ====\")\n",
    "print(df[continuous_cols].skew())\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Correlation Matrix\n",
    "# ------------------------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Target distribution\n",
    "# ------------------------------\n",
    "sns.countplot(x=df[\"Cover_Type\"])\n",
    "plt.title(\"Cover Type Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Trainâ€“Test Split (using cleaned + log-transformed data)\n",
    "# ------------------------------\n",
    "X = df.drop(\"Cover_Type\", axis=1)\n",
    "y = df[\"Cover_Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 8. Scaling\n",
    "# ------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------\n",
    "# 9. MODELS (FAST VERSIONS)\n",
    "# ------------------------------\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=500, solver='lbfgs')\n",
    "lr.fit(X_train, y_train)\n",
    "acc_lr = accuracy_score(y_test, lr.predict(X_test))\n",
    "\n",
    "# Linear SVM (fastest)\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "acc_svm = accuracy_score(y_test, svm.predict(X_test))\n",
    "\n",
    "# MLP Neural Network\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(32, 16), max_iter=100, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "acc_mlp = accuracy_score(y_test, mlp.predict(X_test))\n",
    "\n",
    "# ------------------------------\n",
    "# 10. Compare Results\n",
    "# ------------------------------\n",
    "scores = {\n",
    "    \"Logistic Regression\": acc_lr,\n",
    "    \"Linear SVM\": acc_svm,\n",
    "    \"MLP Neural Network\": acc_mlp\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(scores.keys(), scores.values())\n",
    "plt.title(\"Model Accuracy Comparison (AFTER CLEANING & DESKEW)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== FINAL ACCURACIES ===\")\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
