{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d7a31",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "\n",
    "# def preprocess_data_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     # 1. Define Numerical Columns\n",
    "#     # Target: 'smoking' is excluded. Binary/Ordinal (hearing, Urine protein, dental caries) are also excluded.\n",
    "#     numerical_cols = [\n",
    "#         'age', 'height(cm)', 'weight(kg)', 'waist(cm)',\n",
    "#         'eyesight(left)', 'eyesight(right)', 'systolic', 'relaxation',\n",
    "#         'fasting blood sugar', 'Cholesterol', 'triglyceride', 'HDL', 'LDL',\n",
    "#         'hemoglobin', 'serum creatinine', 'AST', 'ALT', 'Gtp'\n",
    "#     ]\n",
    "\n",
    "#     df_processed = df.copy()\n",
    "\n",
    "#     # 2. Outlier Removal (IQR Capping)\n",
    "#     for col in numerical_cols:\n",
    "#         Q1 = df_processed[col].quantile(0.25)\n",
    "#         Q3 = df_processed[col].quantile(0.75)\n",
    "#         IQR = Q3 - Q1\n",
    "#         lower_bound = Q1 - 1.5 * IQR\n",
    "#         upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "#         # Cap the values to the calculated bounds\n",
    "#         df_processed[col] = np.where(\n",
    "#             df_processed[col] < lower_bound,\n",
    "#             lower_bound,\n",
    "#             df_processed[col]\n",
    "#         )\n",
    "#         df_processed[col] = np.where(\n",
    "#             df_processed[col] > upper_bound,\n",
    "#             upper_bound,\n",
    "#             df_processed[col]\n",
    "#         )\n",
    "\n",
    "#     # 3. Skewness Reduction (Log Transformation)\n",
    "#     # Recalculate skewness after outlier treatment for a precise transformation\n",
    "#     skewness_after_outliers = df_processed[numerical_cols].skew()\n",
    "#     # Apply np.log1p to columns with absolute skewness > 0.75\n",
    "#     highly_skewed_cols = skewness_after_outliers[abs(skewness_after_outliers) > 0.75].index.tolist()\n",
    "\n",
    "#     for col in highly_skewed_cols:\n",
    "#         # np.log1p (log(1+x)) is used for positive skewness and to handle values close to zero.\n",
    "#         df_processed[col] = np.log1p(df_processed[col])\n",
    "\n",
    "#     return df_processed\n",
    "\n",
    "def preprocess_data_drop_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies outlier removal (Dropping) and skewness reduction (np.log1p)\n",
    "    to numerical columns in the DataFrame.\n",
    "\n",
    "    Rows where at least one numerical feature is an outlier (based on\n",
    "    1.5 * IQR) are removed entirely.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        The processed DataFrame with outliers dropped and features transformed.\n",
    "    \"\"\"\n",
    "    # 1. Define Numerical Columns\n",
    "    numerical_cols = [\n",
    "        'age', 'height(cm)', 'weight(kg)', 'waist(cm)',\n",
    "        'eyesight(left)', 'eyesight(right)', 'systolic', 'relaxation',\n",
    "        'fasting blood sugar', 'Cholesterol', 'triglyceride', 'HDL', 'LDL',\n",
    "        'hemoglobin', 'serum creatinine', 'AST', 'ALT', 'Gtp'\n",
    "    ]\n",
    "\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # 2. Outlier Removal (Dropping rows)\n",
    "    # Initialize mask to True for all rows\n",
    "    outlier_mask = pd.Series(True, index=df_processed.index)\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        Q1 = df_processed[col].quantile(0.25)\n",
    "        Q3 = df_processed[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Create mask for values within bounds for the current column\n",
    "        col_mask = (df_processed[col] >= lower_bound) & (df_processed[col] <= upper_bound)\n",
    "        \n",
    "        # Combine the column mask with the overall mask using logical AND\n",
    "        # This ensures only rows where ALL numerical columns are NOT outliers are kept.\n",
    "        outlier_mask = outlier_mask & col_mask\n",
    "\n",
    "    # Filter the DataFrame to keep only non-outlier rows\n",
    "    df_processed = df_processed[outlier_mask]\n",
    "\n",
    "    # 3. Skewness Reduction (Log Transformation)\n",
    "    # Recalculate skewness on the cleaned data\n",
    "    skewness_after_outliers = df_processed[numerical_cols].skew()\n",
    "    # Apply np.log1p to columns with absolute skewness > 0.75\n",
    "    highly_skewed_cols = skewness_after_outliers[abs(skewness_after_outliers) > 0.75].index.tolist()\n",
    "    \n",
    "    for col in highly_skewed_cols:\n",
    "        df_processed[col] = np.log1p(df_processed[col])\n",
    "\n",
    "    return df_processed\n",
    "\n",
    "train_df = pd.read_csv(\"/content/train_dataset.csv\")\n",
    "#test_df = pd.read_csv(\"/content/test_dataset.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "#print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "\n",
    "train_df.info()\n",
    "train_df.describe()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "train_df['smoking'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Class Balance in Training Data\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(train_df.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_df = preprocess_data_drop_outliers(train_df)\n",
    "\n",
    "train_df.info()\n",
    "train_df.describe()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "train_df['smoking'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Class Balance in Training Data\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(train_df.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# X_train = train_df.drop(columns=['smoking'])\n",
    "# y_train = train_df['smoking']\n",
    "\n",
    "# X_test = test_df.drop(columns=['smoking'])\n",
    "# y_test = test_df['smoking']\n",
    "# print(X_train.shape, X_test.shape)\n",
    "\n",
    "\n",
    "X = train_df.drop(columns=['smoking'])\n",
    "y = train_df['smoking']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Scaling complete.\")\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(\n",
    "    # C=1.0,        # placeholder\n",
    "    # max_iter=300\n",
    ")\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC(\n",
    "    # C=1.0,        # placeholder\n",
    "     kernel='rbf', # placeholder\n",
    "     probability=True\n",
    ")\n",
    "\n",
    "# Neural Network\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 128, 32),  # placeholder\n",
    "    # activation='relu',            # placeholder\n",
    "    # learning_rate_init=0.001,     # placeholder\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"SVM\": svm_model,\n",
    "    \"Neural Network (MLP)\": mlp\n",
    "}\n",
    "\n",
    "results = {\"Model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": []}\n",
    "\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(X_test_scaled)\n",
    "\n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"Accuracy\"].append(accuracy_score(y_test, preds))\n",
    "    results[\"Precision\"].append(precision_score(y_test, preds))\n",
    "    results[\"Recall\"].append(recall_score(y_test, preds))\n",
    "    results[\"F1 Score\"].append(f1_score(y_test, preds))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(results_df['Model'], results_df['Accuracy'])\n",
    "plt.title(\"Accuracy Comparison\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(results_df['Model'], results_df['F1 Score'])\n",
    "plt.title(\"F1 Score Comparison\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_model_name = results_df.sort_values(\"Accuracy\", ascending=False).iloc[0][\"Model\"]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(\"Best Model:\", best_model_name)\n",
    "\n",
    "best_preds = best_model.predict(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_test, best_preds)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(f\"Confusion Matrix - {best_model_name}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "inference_df = pd.read_csv(\"/content/test_dataset.csv\")\n",
    "\n",
    "print(\"Inference input shape:\", inference_df.shape)\n",
    "inference_df.head()\n",
    "\n",
    "\n",
    "inference_scaled = scaler.transform(inference_df)\n",
    "\n",
    "inference_preds = best_model.predict(inference_scaled)\n",
    "\n",
    "output_df = pd.DataFrame({\n",
    "    \"Input_Index\": inference_df.index,\n",
    "    \"Predicted_Smoking\": inference_preds\n",
    "})\n",
    "\n",
    "output_df\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
